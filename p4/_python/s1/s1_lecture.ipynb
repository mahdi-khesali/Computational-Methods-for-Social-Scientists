{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acd031ba7d6e32fc",
   "metadata": {},
   "source": [
    "- Points:\n",
    "    - You can do one thing in multiple ways.\n",
    "        - How do you decide which path you take:\n",
    "                - The most important factor is efficiency of your code: How fast your code can be run?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "006212cd-97c2-4fbc-b511-54356e393f97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T16:04:49.991863Z",
     "start_time": "2025-07-24T16:04:49.985867Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "def countdown_timer(seconds):\n",
    "    for i in range(seconds, -1, -1):\n",
    "        clear_output(wait=True)\n",
    "        print(f\"⏳ Time remaining: {i} seconds\")\n",
    "        time.sleep(1)\n",
    "    print(\"✅ Time's up!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d6e645-cb93-42f0-bf6d-ae50cd649e9d",
   "metadata": {},
   "source": [
    "# Text and its features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "33d6a13f-1bf4-4a15-801f-4ac4afcb5279",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T16:07:31.911303Z",
     "start_time": "2025-07-24T16:07:31.906686Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import string\n",
    "import pandas as pd \n",
    "import nltk # this the basic and traditional package for text analysis in python \n",
    "import readability # this the basic package for measuring linguistic features of a text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "94fe7046-2d07-4794-aef9-1e4c35c393db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = \"Your long text goes here...\"\n",
    "\n",
    "results = readability.getmeasures(text, lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0ae7ede2-2bc1-4a7d-8b72-1aa988a1155c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['readability grades']['FleschReadingEase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8ae73cbf-ed56-44f6-b5a6-fd2ce9dc6d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('readability grades',\n",
       "              OrderedDict([('Kincaid', 0.5199999999999996),\n",
       "                           ('ARI', 2.735999999999997),\n",
       "                           ('Coleman-Liau', 5.329054600000006),\n",
       "                           ('FleschReadingEase', 100.24000000000001),\n",
       "                           ('GunningFogIndex', 2.0),\n",
       "                           ('LIX', 25.0),\n",
       "                           ('SMOGIndex', 3.0),\n",
       "                           ('RIX', 1.0),\n",
       "                           ('DaleChallIndex', 6.564000000000001)])),\n",
       "             ('sentence info',\n",
       "              OrderedDict([('characters_per_word', 4.6),\n",
       "                           ('syll_per_word', 1.2),\n",
       "                           ('words_per_sentence', 5.0),\n",
       "                           ('sentences_per_paragraph', 1.0),\n",
       "                           ('type_token_ratio', 1.0),\n",
       "                           ('directspeech_ratio', 0.0),\n",
       "                           ('characters', 23),\n",
       "                           ('syllables', 6),\n",
       "                           ('words', 5),\n",
       "                           ('wordtypes', 5),\n",
       "                           ('sentences', 1),\n",
       "                           ('paragraphs', 1),\n",
       "                           ('long_words', 1),\n",
       "                           ('complex_words', 0),\n",
       "                           ('complex_words_dc', 2)])),\n",
       "             ('word usage',\n",
       "              OrderedDict([('tobeverb', 0),\n",
       "                           ('auxverb', 0),\n",
       "                           ('conjunction', 0),\n",
       "                           ('pronoun', 1),\n",
       "                           ('preposition', 0),\n",
       "                           ('nominalization', 0)])),\n",
       "             ('sentence beginnings',\n",
       "              OrderedDict([('pronoun', 1),\n",
       "                           ('interrogative', 0),\n",
       "                           ('article', 0),\n",
       "                           ('subordination', 0),\n",
       "                           ('conjunction', 0),\n",
       "                           ('preposition', 0)]))])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b367627827aa25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T16:04:52.161448Z",
     "start_time": "2025-07-24T16:04:51.799921Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bax1408\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\bax1408\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\bax1408\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bax1408\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42e6de53bbdbe649",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T16:04:54.363423Z",
     "start_time": "2025-07-24T16:04:54.358289Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize stemmer\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48eea6e6-f4ac-497d-ae25-db9d198ac4a0",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "    A{Subject of study} --> B{Text}\n",
    "    B --> | influence | C[Content of Text]\n",
    "    B --> | influence | D[Linguistic Features of Text]\n",
    "```\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64438534-5622-42f9-ab56-0f69eb85e819",
   "metadata": {},
   "source": [
    "## 1.1. Meta data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfd1bfb-c654-454e-82b8-f2e4089a0037",
   "metadata": {},
   "source": [
    "Each text has three types of data that can be useful: \n",
    "\n",
    "- Metadata \n",
    "  - Any information about a text: author, type of text (speech, tweet,...), date of publication, language, etc.\n",
    "    - Sometimes metadata appears in text itself. \n",
    "    \n",
    "    \n",
    "- Textual data \n",
    "  - Linguistic features of text\n",
    "  - Content of text \n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823ac0ed-12b1-479d-9df4-4e3a0de50b0f",
   "metadata": {},
   "source": [
    "**Metadata**\n",
    "\n",
    "- When designing a project containing text analysis think carefully what kind of information you want to gather:\n",
    "  - You have to spend a huge amount of time to recover information that you did not code.\n",
    "\n",
    "- This is information beyond the text and its linguistic features. We refer to them as metadata, such as author, date, type, etc...\n",
    "- 3 ways to store and retrieve metadata\n",
    "  - Working with API\n",
    "  - Store in separate file and retrieve from it.  \n",
    "  - Store in the name of file and retrieve from it.\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff071cf2-b350-4e07-b340-4bdd965acb0a",
   "metadata": {},
   "source": [
    "### Exercise 1.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "715c04c2-6060-424f-8232-cf7b4b241aee",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcountdown_timer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[48], line 6\u001b[0m, in \u001b[0;36mcountdown_timer\u001b[1;34m(seconds)\u001b[0m\n\u001b[0;32m      4\u001b[0m     clear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m⏳ Time remaining: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Time\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms up!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "countdown_timer(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5ec369-e98d-41fb-a18a-154a452c0ca0",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f72ffa-45ca-4bc3-8f04-943572132fc1",
   "metadata": {},
   "source": [
    "**Retrieve metadata from file names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e31173f8-2417-479f-a635-e4216b5954d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T16:05:09.960448Z",
     "start_time": "2025-07-24T16:05:09.450482Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: read the files and store text and file names in a dictionary \n",
    "dictUNSpeech = {} # create an empty dictionary \n",
    "# The directory\n",
    "fileAddress1 = '../../corpusExample/unSpeeches2000_2010'\n",
    "# Open the file one by one - remember you need to tell python each single step - nothing here is automatic. \n",
    "# \n",
    "for file in os.listdir(fileAddress1):\n",
    "    with open(os.path.join(fileAddress1, file), 'r', encoding='utf-8', errors='ignore') as textFile: \n",
    "        text = textFile.read().lower()\n",
    "        dictUNSpeech[file.replace('.txt', '')] =  text\n",
    "\n",
    "# convert the dictionary to a dataframe \n",
    "dfUNSpeech = pd.DataFrame(list(dictUNSpeech.items()), columns=[\"id\", \"text\"])\n",
    "\n",
    "dfUNSpeech[\"isoAlpha\"] = dfUNSpeech[\"id\"].str.split(\"_\", n=2,  expand=True)[0].astype('str')\n",
    "dfUNSpeech[\"session\"] = dfUNSpeech[\"id\"].str.split(\"_\", n=2, expand=True)[1].astype('int')\n",
    "dfUNSpeech[\"year\"] = dfUNSpeech[\"id\"].str.split(\"_\", n=2, expand=True)[2].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fed1413f-63f6-4898-b85e-c1e001ed0d04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T16:05:10.549960Z",
     "start_time": "2025-07-24T16:05:10.542538Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>isoAlpha</th>\n",
       "      <th>session</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG_55_2000</td>\n",
       "      <td>on my way to the\\nassembly hall, i was informe...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>55</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG_56_2001</td>\n",
       "      <td>﻿at the outset, on\\nbehalf of the government o...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG_57_2002</td>\n",
       "      <td>﻿not very far from here stood\\ntwo towers that...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>57</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG_58_2003</td>\n",
       "      <td>﻿there is no reality more\\noppressive than the...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>58</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG_59_2004</td>\n",
       "      <td>nelson mandela once\\ndescribed his countryís t...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>59</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text isoAlpha  \\\n",
       "0  AFG_55_2000  on my way to the\\nassembly hall, i was informe...      AFG   \n",
       "1  AFG_56_2001  ﻿at the outset, on\\nbehalf of the government o...      AFG   \n",
       "2  AFG_57_2002  ﻿not very far from here stood\\ntwo towers that...      AFG   \n",
       "3  AFG_58_2003  ﻿there is no reality more\\noppressive than the...      AFG   \n",
       "4  AFG_59_2004  nelson mandela once\\ndescribed his countryís t...      AFG   \n",
       "\n",
       "   session  year  \n",
       "0       55  2000  \n",
       "1       56  2001  \n",
       "2       57  2002  \n",
       "3       58  2003  \n",
       "4       59  2004  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfUNSpeech.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228594ee-127b-426d-8344-46936f69995f",
   "metadata": {},
   "source": [
    "**Example 2: Retreieve from Separate File** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea5f6d63-3165-452f-9670-e894eb16c9a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T16:05:13.562162Z",
     "start_time": "2025-07-24T16:05:13.461705Z"
    }
   },
   "outputs": [],
   "source": [
    "fileAddress2 = '../../corpusExample/speakersSession.xlsx'\n",
    "speakerData = pd.read_excel(fileAddress2)\n",
    "dfUNSpeechComplete = dfUNSpeech.merge(speakerData, on=['year', 'isoAlpha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c49be6e3-3bab-4b30-ac22-eea3850f58bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T16:05:14.790812Z",
     "start_time": "2025-07-24T16:05:14.782313Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>isoAlpha</th>\n",
       "      <th>session</th>\n",
       "      <th>year</th>\n",
       "      <th>Session</th>\n",
       "      <th>cname</th>\n",
       "      <th>speakerName</th>\n",
       "      <th>post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG_55_2000</td>\n",
       "      <td>on my way to the\\nassembly hall, i was informe...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>55</td>\n",
       "      <td>2000</td>\n",
       "      <td>55</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Abdullah Abdullah</td>\n",
       "      <td>MFA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG_56_2001</td>\n",
       "      <td>﻿at the outset, on\\nbehalf of the government o...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>56</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Ravan Farhâdi</td>\n",
       "      <td>UN_Rep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG_57_2002</td>\n",
       "      <td>﻿not very far from here stood\\ntwo towers that...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>57</td>\n",
       "      <td>2002</td>\n",
       "      <td>57</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Hâmid Karzai</td>\n",
       "      <td>President</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG_58_2003</td>\n",
       "      <td>﻿there is no reality more\\noppressive than the...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>58</td>\n",
       "      <td>2003</td>\n",
       "      <td>58</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Hâmid Karzai</td>\n",
       "      <td>President</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG_59_2004</td>\n",
       "      <td>nelson mandela once\\ndescribed his countryís t...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>59</td>\n",
       "      <td>2004</td>\n",
       "      <td>59</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Mr. Hamid Karzai</td>\n",
       "      <td>President</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text isoAlpha  \\\n",
       "0  AFG_55_2000  on my way to the\\nassembly hall, i was informe...      AFG   \n",
       "1  AFG_56_2001  ﻿at the outset, on\\nbehalf of the government o...      AFG   \n",
       "2  AFG_57_2002  ﻿not very far from here stood\\ntwo towers that...      AFG   \n",
       "3  AFG_58_2003  ﻿there is no reality more\\noppressive than the...      AFG   \n",
       "4  AFG_59_2004  nelson mandela once\\ndescribed his countryís t...      AFG   \n",
       "\n",
       "   session  year  Session        cname        speakerName       post  \n",
       "0       55  2000       55  Afghanistan  Abdullah Abdullah        MFA  \n",
       "1       56  2001       56  Afghanistan      Ravan Farhâdi     UN_Rep  \n",
       "2       57  2002       57  Afghanistan       Hâmid Karzai  President  \n",
       "3       58  2003       58  Afghanistan       Hâmid Karzai  President  \n",
       "4       59  2004       59  Afghanistan   Mr. Hamid Karzai  President  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfUNSpeechComplete.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83b4c46-4258-46d5-bd86-2cdf5c57253e",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "**Some Abbreviation** \n",
    "- Prime Minister: PM \n",
    "- Deputy Prime Minister: DPM \n",
    "- Head of Government: HOG\n",
    "- Head of State: HOS\n",
    "- Minister for Foreign Affairs: MFA\n",
    "- UN Representative: UN_rep\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35e65cd-427d-4916-9a33-ec252a6faf02",
   "metadata": {},
   "source": [
    "**Example 3: working with API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e06a5f-d057-453d-a4d8-3a47dd711d3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T16:05:25.277526Z",
     "start_time": "2025-07-24T16:05:25.274480Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2e890f5-e80f-4af4-a844-87890bfdc674",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab14ecf-b143-4ee6-9eb3-32233a62426f",
   "metadata": {},
   "source": [
    "### Exercise 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3f83c7e-2d2c-4867-aa21-5f116de2eea1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcountdown_timer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m, in \u001b[0;36mcountdown_timer\u001b[1;34m(seconds)\u001b[0m\n\u001b[0;32m      4\u001b[0m     clear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m⏳ Time remaining: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Time\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms up!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "countdown_timer(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f5c741dab19afe",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23aff61-b44c-4c75-9a0b-e5b14ef1b774",
   "metadata": {},
   "source": [
    "## 1.2. Linguistic Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72febbb8-d2c9-4644-9591-9de73cdc46c0",
   "metadata": {},
   "source": [
    "**How Does Linguistic Features help us?**\n",
    "Sometimes we do not need a complex method to achieve our goal. \n",
    "\n",
    "Simple measurements are useful. \n",
    "\n",
    "Some linguistic features:\n",
    "- Length of text\n",
    "- Number of sentences \n",
    "- Length of sentences \n",
    "- Complexity of text\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd8beac7a16e1e8",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcdfa6baf5e26e",
   "metadata": {},
   "source": [
    "**Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1a98b3a-dab5-4adf-9904-3ca8d594eb4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T16:05:36.296641Z",
     "start_time": "2025-07-24T16:05:36.046742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>isoAlpha</th>\n",
       "      <th>session</th>\n",
       "      <th>year</th>\n",
       "      <th>Session</th>\n",
       "      <th>cname</th>\n",
       "      <th>speakerName</th>\n",
       "      <th>post</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG_55_2000</td>\n",
       "      <td>on my way to the\\nassembly hall, i was informe...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>55</td>\n",
       "      <td>2000</td>\n",
       "      <td>55</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Abdullah Abdullah</td>\n",
       "      <td>MFA</td>\n",
       "      <td>2873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG_56_2001</td>\n",
       "      <td>﻿at the outset, on\\nbehalf of the government o...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>56</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Ravan Farhâdi</td>\n",
       "      <td>UN_Rep</td>\n",
       "      <td>2073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG_57_2002</td>\n",
       "      <td>﻿not very far from here stood\\ntwo towers that...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>57</td>\n",
       "      <td>2002</td>\n",
       "      <td>57</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Hâmid Karzai</td>\n",
       "      <td>President</td>\n",
       "      <td>1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG_58_2003</td>\n",
       "      <td>﻿there is no reality more\\noppressive than the...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>58</td>\n",
       "      <td>2003</td>\n",
       "      <td>58</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Hâmid Karzai</td>\n",
       "      <td>President</td>\n",
       "      <td>1617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG_59_2004</td>\n",
       "      <td>nelson mandela once\\ndescribed his countryís t...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>59</td>\n",
       "      <td>2004</td>\n",
       "      <td>59</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Mr. Hamid Karzai</td>\n",
       "      <td>President</td>\n",
       "      <td>1096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>ZWE_61_2006</td>\n",
       "      <td>let me begin my statement \\nby echoing the sen...</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>61</td>\n",
       "      <td>2006</td>\n",
       "      <td>61</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Mr. Robert Gabriel Mugabe</td>\n",
       "      <td>President</td>\n",
       "      <td>2371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>ZWE_62_2007</td>\n",
       "      <td>allow me to congratulate \\nmr. kerim on his el...</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>62</td>\n",
       "      <td>2007</td>\n",
       "      <td>62</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Robert G. Mugabe</td>\n",
       "      <td>President</td>\n",
       "      <td>2052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <td>ZWE_63_2008</td>\n",
       "      <td>i wish to begin by joining \\nthose who have co...</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>63</td>\n",
       "      <td>2008</td>\n",
       "      <td>63</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Robert Mugabe</td>\n",
       "      <td>President</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>ZWE_64_2009</td>\n",
       "      <td>let me begin by extending \\nour warmest congra...</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>64</td>\n",
       "      <td>2009</td>\n",
       "      <td>64</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Robert G. Mugabe</td>\n",
       "      <td>President</td>\n",
       "      <td>1722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>ZWE_65_2010</td>\n",
       "      <td>allow me once again to \\nextend to you, sir, o...</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>65</td>\n",
       "      <td>2010</td>\n",
       "      <td>65</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Robert G. Mugabe</td>\n",
       "      <td>President</td>\n",
       "      <td>1558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2077 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                               text isoAlpha  \\\n",
       "0     AFG_55_2000  on my way to the\\nassembly hall, i was informe...      AFG   \n",
       "1     AFG_56_2001  ﻿at the outset, on\\nbehalf of the government o...      AFG   \n",
       "2     AFG_57_2002  ﻿not very far from here stood\\ntwo towers that...      AFG   \n",
       "3     AFG_58_2003  ﻿there is no reality more\\noppressive than the...      AFG   \n",
       "4     AFG_59_2004  nelson mandela once\\ndescribed his countryís t...      AFG   \n",
       "...           ...                                                ...      ...   \n",
       "2072  ZWE_61_2006  let me begin my statement \\nby echoing the sen...      ZWE   \n",
       "2073  ZWE_62_2007  allow me to congratulate \\nmr. kerim on his el...      ZWE   \n",
       "2074  ZWE_63_2008  i wish to begin by joining \\nthose who have co...      ZWE   \n",
       "2075  ZWE_64_2009  let me begin by extending \\nour warmest congra...      ZWE   \n",
       "2076  ZWE_65_2010  allow me once again to \\nextend to you, sir, o...      ZWE   \n",
       "\n",
       "      session  year  Session        cname                speakerName  \\\n",
       "0          55  2000       55  Afghanistan          Abdullah Abdullah   \n",
       "1          56  2001       56  Afghanistan              Ravan Farhâdi   \n",
       "2          57  2002       57  Afghanistan               Hâmid Karzai   \n",
       "3          58  2003       58  Afghanistan               Hâmid Karzai   \n",
       "4          59  2004       59  Afghanistan           Mr. Hamid Karzai   \n",
       "...       ...   ...      ...          ...                        ...   \n",
       "2072       61  2006       61     Zimbabwe  Mr. Robert Gabriel Mugabe   \n",
       "2073       62  2007       62     Zimbabwe           Robert G. Mugabe   \n",
       "2074       63  2008       63     Zimbabwe              Robert Mugabe   \n",
       "2075       64  2009       64     Zimbabwe           Robert G. Mugabe   \n",
       "2076       65  2010       65     Zimbabwe           Robert G. Mugabe   \n",
       "\n",
       "           post  word_count  \n",
       "0           MFA        2873  \n",
       "1        UN_Rep        2073  \n",
       "2     President        1700  \n",
       "3     President        1617  \n",
       "4     President        1096  \n",
       "...         ...         ...  \n",
       "2072  President        2371  \n",
       "2073  President        2052  \n",
       "2074  President        1800  \n",
       "2075  President        1722  \n",
       "2076  President        1558  \n",
       "\n",
       "[2077 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the length of each text \n",
    "dfUNSpeechComplete['word_count'] = dfUNSpeechComplete['text'].str.split().str.len()\n",
    "dfUNSpeechComplete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abb5cd8da584dc1",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521aeba8c942e793",
   "metadata": {},
   "source": [
    "**Example: counting the number of sentences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf46da03-ba4d-470b-894b-7e80bf3faae9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T16:05:43.330450Z",
     "start_time": "2025-07-24T16:05:41.556284Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply sentence tokenizer\n",
    "dfUNSpeechComplete['sentence_count'] = dfUNSpeechComplete['text'].apply(lambda x: len(nltk.tokenize.sent_tokenize(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ecb02a-2d0a-416c-9d31-857ba40b3e80",
   "metadata": {},
   "source": [
    "- You can count the number of sentences using spaCy as well. We will come to that later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b351f062e59a7a73",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b78ecd421e5009",
   "metadata": {},
   "source": [
    "**Example: looking at the frequency of speeches from different officials**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4adebe77-81bc-4d9d-90be-3bf8a0f864c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T16:05:45.320228Z",
     "start_time": "2025-07-24T16:05:45.312594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "post\n",
       "MFA            955\n",
       "President      533\n",
       "PM             221\n",
       "UN_Rep         187\n",
       "DPM            109\n",
       "V-President     34\n",
       "HOS             24\n",
       "HOG             14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfUNSpeechComplete['post'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3571b4c889773050",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb0514e-84f4-4582-a4c1-021b46132af7",
   "metadata": {},
   "source": [
    "**Features of Text that could be interesting:**\n",
    "- Length \n",
    "- Readability \n",
    "- Entropy\n",
    "- Lexical diversity\n",
    "- Tenses of verbs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c821628c-db2c-4af8-bdaa-ed4d7bf0df61",
   "metadata": {},
   "source": [
    "**Example: linguistic features such as readability scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "34363a7b-8cad-475c-adc0-10012bc8740d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('readability grades',\n",
       "              OrderedDict([('Kincaid', 6.550869565217393),\n",
       "                           ('ARI', 7.63644927536232),\n",
       "                           ('Coleman-Liau', 8.984565978260871),\n",
       "                           ('FleschReadingEase', 75.40644927536233),\n",
       "                           ('GunningFogIndex', 8.742028985507247),\n",
       "                           ('LIX', 41.42028985507246),\n",
       "                           ('SMOGIndex', 8.477225575051662),\n",
       "                           ('RIX', 4.0),\n",
       "                           ('DaleChallIndex', 3.5066202898550727)])),\n",
       "             ('sentence info',\n",
       "              OrderedDict([('characters_per_word', 4.543478260869565),\n",
       "                           ('syll_per_word', 1.3695652173913044),\n",
       "                           ('words_per_sentence', 15.333333333333334),\n",
       "                           ('sentences_per_paragraph', 1.5),\n",
       "                           ('type_token_ratio', 0.7391304347826086),\n",
       "                           ('directspeech_ratio', 0.0),\n",
       "                           ('characters', 209),\n",
       "                           ('syllables', 63),\n",
       "                           ('words', 46),\n",
       "                           ('wordtypes', 34),\n",
       "                           ('sentences', 3),\n",
       "                           ('paragraphs', 2),\n",
       "                           ('long_words', 12),\n",
       "                           ('complex_words', 3),\n",
       "                           ('complex_words_dc', 8)])),\n",
       "             ('word usage',\n",
       "              OrderedDict([('tobeverb', 5),\n",
       "                           ('auxverb', 0),\n",
       "                           ('conjunction', 3),\n",
       "                           ('pronoun', 5),\n",
       "                           ('preposition', 7),\n",
       "                           ('nominalization', 0)])),\n",
       "             ('sentence beginnings',\n",
       "              OrderedDict([('pronoun', 2),\n",
       "                           ('interrogative', 0),\n",
       "                           ('article', 0),\n",
       "                           ('subordination', 0),\n",
       "                           ('conjunction', 0),\n",
       "                           ('preposition', 0)]))])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SmallText = \"\"\" \n",
    "This is ILE summer school. It is held in Hamburg at the institute for Law and Economics where is one of its kind in Europe. \n",
    "\n",
    "This is the week of methods. We go through computational and experimental methods, which are common in Law and Economics research. \n",
    "\"\"\"\n",
    "\n",
    "linguisticFeatures = readability.getmeasures(SmallText, lang='en')\n",
    "linguisticFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a874d31a-f60d-455c-bf51-a2cfcd26d8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure readability using Flesch Reading Ease\n",
    "dfUNSpeechComplete['flesch_reading_ease'] = dfUNSpeechComplete['text'].apply(lambda x: readability.getmeasures(x, lang='en')['readability grades']['FleschReadingEase'])\n",
    "dfUNSpeechComplete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f19c167cc3d883f",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d816c04d65c91dbf",
   "metadata": {},
   "source": [
    "### Exercise 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aedae03a3f2808",
   "metadata": {},
   "outputs": [],
   "source": [
    "countdown_timer(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320aa5fa68d99e9",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3fba223045b50d",
   "metadata": {},
   "source": [
    "**Tokenization**\n",
    " - The next step in analyzing text, is to break down the documents into elements that can be quantified.\n",
    "  - The basic element in each document is called *token*.\n",
    "  - Does token mean word? Not necessarily. But token usually corresponds to a word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4d9a199a3df308",
   "metadata": {},
   "source": [
    "**NLTK**\n",
    "- In the good old days (almost 8 years ago), the package *NLTK* was the main package for doing basic NLP tasks.\n",
    "- Here we use it to break down our documents to words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2985baf66e7d216d",
   "metadata": {},
   "source": [
    "**Example: Tokenization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8c5fb9021671a8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T14:46:44.317457Z",
     "start_time": "2025-07-24T14:46:28.290354Z"
    }
   },
   "outputs": [],
   "source": [
    "dfUNSpeechComplete['tokens'] = dfUNSpeechComplete['text'].apply(nltk.tokenize.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc22b90aca4a6b03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T14:46:47.888795Z",
     "start_time": "2025-07-24T14:46:47.874237Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>isoAlpha</th>\n",
       "      <th>session</th>\n",
       "      <th>year</th>\n",
       "      <th>Session</th>\n",
       "      <th>cname</th>\n",
       "      <th>speakerName</th>\n",
       "      <th>post</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG_55_2000</td>\n",
       "      <td>On my way to the\\nAssembly Hall, I was informe...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>55</td>\n",
       "      <td>2000</td>\n",
       "      <td>55</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Abdullah Abdullah</td>\n",
       "      <td>MFA</td>\n",
       "      <td>2873</td>\n",
       "      <td>67</td>\n",
       "      <td>[On, my, way, to, the, Assembly, Hall, ,, I, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG_56_2001</td>\n",
       "      <td>﻿At the outset, on\\nbehalf of the Government o...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>56</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Ravan Farhâdi</td>\n",
       "      <td>UN_Rep</td>\n",
       "      <td>2073</td>\n",
       "      <td>81</td>\n",
       "      <td>[﻿At, the, outset, ,, on, behalf, of, the, Gov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG_57_2002</td>\n",
       "      <td>﻿Not very far from here stood\\ntwo towers that...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>57</td>\n",
       "      <td>2002</td>\n",
       "      <td>57</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Hâmid Karzai</td>\n",
       "      <td>President</td>\n",
       "      <td>1700</td>\n",
       "      <td>62</td>\n",
       "      <td>[﻿Not, very, far, from, here, stood, two, towe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG_58_2003</td>\n",
       "      <td>﻿There is no reality more\\noppressive than the...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>58</td>\n",
       "      <td>2003</td>\n",
       "      <td>58</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Hâmid Karzai</td>\n",
       "      <td>President</td>\n",
       "      <td>1617</td>\n",
       "      <td>83</td>\n",
       "      <td>[﻿There, is, no, reality, more, oppressive, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG_59_2004</td>\n",
       "      <td>Nelson Mandela once\\ndescribed his countryís t...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>59</td>\n",
       "      <td>2004</td>\n",
       "      <td>59</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Mr. Hamid Karzai</td>\n",
       "      <td>President</td>\n",
       "      <td>1096</td>\n",
       "      <td>56</td>\n",
       "      <td>[Nelson, Mandela, once, described, his, countr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>ZWE_61_2006</td>\n",
       "      <td>Let me begin my statement \\nby echoing the sen...</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>61</td>\n",
       "      <td>2006</td>\n",
       "      <td>61</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Mr. Robert Gabriel Mugabe</td>\n",
       "      <td>President</td>\n",
       "      <td>2371</td>\n",
       "      <td>100</td>\n",
       "      <td>[Let, me, begin, my, statement, by, echoing, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>ZWE_62_2007</td>\n",
       "      <td>Allow me to congratulate \\nMr. Kerim on his el...</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>62</td>\n",
       "      <td>2007</td>\n",
       "      <td>62</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Robert G. Mugabe</td>\n",
       "      <td>President</td>\n",
       "      <td>2052</td>\n",
       "      <td>121</td>\n",
       "      <td>[Allow, me, to, congratulate, Mr., Kerim, on, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <td>ZWE_63_2008</td>\n",
       "      <td>I wish to begin by joining \\nthose who have co...</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>63</td>\n",
       "      <td>2008</td>\n",
       "      <td>63</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Robert Mugabe</td>\n",
       "      <td>President</td>\n",
       "      <td>1800</td>\n",
       "      <td>65</td>\n",
       "      <td>[I, wish, to, begin, by, joining, those, who, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>ZWE_64_2009</td>\n",
       "      <td>Let me begin by extending \\nour warmest congra...</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>64</td>\n",
       "      <td>2009</td>\n",
       "      <td>64</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Robert G. Mugabe</td>\n",
       "      <td>President</td>\n",
       "      <td>1722</td>\n",
       "      <td>63</td>\n",
       "      <td>[Let, me, begin, by, extending, our, warmest, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>ZWE_65_2010</td>\n",
       "      <td>Allow me once again to \\nextend to you, Sir, o...</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>65</td>\n",
       "      <td>2010</td>\n",
       "      <td>65</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Robert G. Mugabe</td>\n",
       "      <td>President</td>\n",
       "      <td>1558</td>\n",
       "      <td>68</td>\n",
       "      <td>[Allow, me, once, again, to, extend, to, you, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2077 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                               text isoAlpha  \\\n",
       "0     AFG_55_2000  On my way to the\\nAssembly Hall, I was informe...      AFG   \n",
       "1     AFG_56_2001  ﻿At the outset, on\\nbehalf of the Government o...      AFG   \n",
       "2     AFG_57_2002  ﻿Not very far from here stood\\ntwo towers that...      AFG   \n",
       "3     AFG_58_2003  ﻿There is no reality more\\noppressive than the...      AFG   \n",
       "4     AFG_59_2004  Nelson Mandela once\\ndescribed his countryís t...      AFG   \n",
       "...           ...                                                ...      ...   \n",
       "2072  ZWE_61_2006  Let me begin my statement \\nby echoing the sen...      ZWE   \n",
       "2073  ZWE_62_2007  Allow me to congratulate \\nMr. Kerim on his el...      ZWE   \n",
       "2074  ZWE_63_2008  I wish to begin by joining \\nthose who have co...      ZWE   \n",
       "2075  ZWE_64_2009  Let me begin by extending \\nour warmest congra...      ZWE   \n",
       "2076  ZWE_65_2010  Allow me once again to \\nextend to you, Sir, o...      ZWE   \n",
       "\n",
       "      session  year  Session        cname                speakerName  \\\n",
       "0          55  2000       55  Afghanistan          Abdullah Abdullah   \n",
       "1          56  2001       56  Afghanistan              Ravan Farhâdi   \n",
       "2          57  2002       57  Afghanistan               Hâmid Karzai   \n",
       "3          58  2003       58  Afghanistan               Hâmid Karzai   \n",
       "4          59  2004       59  Afghanistan           Mr. Hamid Karzai   \n",
       "...       ...   ...      ...          ...                        ...   \n",
       "2072       61  2006       61     Zimbabwe  Mr. Robert Gabriel Mugabe   \n",
       "2073       62  2007       62     Zimbabwe           Robert G. Mugabe   \n",
       "2074       63  2008       63     Zimbabwe              Robert Mugabe   \n",
       "2075       64  2009       64     Zimbabwe           Robert G. Mugabe   \n",
       "2076       65  2010       65     Zimbabwe           Robert G. Mugabe   \n",
       "\n",
       "           post  word_count  sentence_count  \\\n",
       "0           MFA        2873              67   \n",
       "1        UN_Rep        2073              81   \n",
       "2     President        1700              62   \n",
       "3     President        1617              83   \n",
       "4     President        1096              56   \n",
       "...         ...         ...             ...   \n",
       "2072  President        2371             100   \n",
       "2073  President        2052             121   \n",
       "2074  President        1800              65   \n",
       "2075  President        1722              63   \n",
       "2076  President        1558              68   \n",
       "\n",
       "                                                 tokens  \n",
       "0     [On, my, way, to, the, Assembly, Hall, ,, I, w...  \n",
       "1     [﻿At, the, outset, ,, on, behalf, of, the, Gov...  \n",
       "2     [﻿Not, very, far, from, here, stood, two, towe...  \n",
       "3     [﻿There, is, no, reality, more, oppressive, th...  \n",
       "4     [Nelson, Mandela, once, described, his, countr...  \n",
       "...                                                 ...  \n",
       "2072  [Let, me, begin, my, statement, by, echoing, t...  \n",
       "2073  [Allow, me, to, congratulate, Mr., Kerim, on, ...  \n",
       "2074  [I, wish, to, begin, by, joining, those, who, ...  \n",
       "2075  [Let, me, begin, by, extending, our, warmest, ...  \n",
       "2076  [Allow, me, once, again, to, extend, to, you, ...  \n",
       "\n",
       "[2077 rows x 12 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfUNSpeechComplete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4355ebf82f040f",
   "metadata": {},
   "source": [
    "**spaCy**\n",
    "- You can use *spaCy* to do tokenization for you.\n",
    "- More efficient, more accurate\n",
    "- We come back to spaCy in our last session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fc52345149ce60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T14:59:29.607411Z",
     "start_time": "2025-07-24T14:59:29.603391Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df8ec13fb2ce3e36",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c00253b0ba1e30",
   "metadata": {},
   "source": [
    "### Exersice 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14b9eb4b18d22ed7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcountdown_timer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m, in \u001b[0;36mcountdown_timer\u001b[1;34m(seconds)\u001b[0m\n\u001b[0;32m      4\u001b[0m     clear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m⏳ Time remaining: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Time\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms up!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "countdown_timer(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8e3ecbc7554c9f",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71983c96e2f0974b",
   "metadata": {},
   "source": [
    "**Removing**\n",
    "- Not all tokens are meanigful.\n",
    "- We want to drop those tokens that do not carry any meaning.\n",
    "- The most obvious ones are punctuations and stopwords:\n",
    "    - Stopwords: Pronomens, articles, prepositions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41719206e8dc4a3",
   "metadata": {},
   "source": [
    "**Example: removing words that are not meaningful.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac6767d1e2155dc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:05:52.347328Z",
     "start_time": "2025-07-24T15:05:52.338389Z"
    }
   },
   "outputs": [],
   "source": [
    "# English stopwords and punctuation\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "punctuations = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a1ce8253f6e77e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:07:43.096810Z",
     "start_time": "2025-07-24T15:07:25.917264Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to clean tokens\n",
    "def text_cleaner(text):\n",
    "    tokens = nltk.tokenize.word_tokenize(text)\n",
    "    return [word.lower() for word in tokens if word.lower() not in stop_words and word not in punctuations]\n",
    "\n",
    "# Apply cleaning\n",
    "dfUNSpeechComplete['tokens_clean'] = dfUNSpeechComplete['text'].apply(text_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc2f8c2f832b8e21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:09:10.021428Z",
     "start_time": "2025-07-24T15:09:10.013320Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokens          [On, my, way, to, the, Assembly, Hall, ,, I, w...\n",
       "tokens_clean    [way, assembly, hall, informed, supreme, state...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the first row and two specific variables (columns)\n",
    "dfUNSpeechComplete.iloc[0][['tokens', 'tokens_clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "988ce20f493015c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:13:13.298154Z",
     "start_time": "2025-07-24T15:13:13.292509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of tokens: 3173 \n",
      " length of clean tokens: 1622\n"
     ]
    }
   ],
   "source": [
    "print(\"length of tokens:\", len(dfUNSpeechComplete.loc[0, 'tokens']), \"\\n\",\n",
    "      \"length of clean tokens:\", len(dfUNSpeechComplete.loc[0, 'tokens_clean'])\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "84f2367845a129b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:50:13.422133Z",
     "start_time": "2025-07-24T15:50:13.416166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of tokens: 1057 \n",
      " length of clean tokens: 932\n"
     ]
    }
   ],
   "source": [
    "print(\"length of tokens:\", len(set(dfUNSpeechComplete.loc[0, 'tokens'])), \"\\n\",\n",
    "      \"length of clean tokens:\", len(set(dfUNSpeechComplete.loc[0, 'tokens_clean']))\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14339c679811d40e",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34184c6294a8593",
   "metadata": {},
   "source": [
    "### Exercise 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae81b42a1c7df30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T14:27:18.573524Z",
     "start_time": "2025-07-24T14:27:18.569818Z"
    }
   },
   "outputs": [],
   "source": [
    "countdown_timer(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b59185631bcd52a",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bf320a173cf145",
   "metadata": {},
   "source": [
    "**Words that are similar but not identical**\n",
    "- What is the difference between run, running and runs?\n",
    "    - There is no difference in their meaning.\n",
    "    - But from the perspective of tokenizer they are separate words.\n",
    "- Solution to the problem:\n",
    "    - Stemming\n",
    "    - Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6b4a0682ccf18",
   "metadata": {},
   "source": [
    "**Stemming**\n",
    "- We cut a few alphabets at the end of words:\n",
    "    - run, run, run: we will have the same words 3 times instead of 3 different words just one time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd88b2d34b57bcdb",
   "metadata": {},
   "source": [
    "**Example: Stemming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "790eaf143f62d61e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T16:13:47.298706Z",
     "start_time": "2025-07-24T16:13:11.647203Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to clean and stem tokens\n",
    "def text_cleaner(text):\n",
    "    tokens = nltk.tokenize.word_tokenize(text)\n",
    "    cleaned_tokens = [word.lower() for word in tokens if word.lower() not in stop_words and word not in punctuations]\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in cleaned_tokens]\n",
    "    return cleaned_tokens, stemmed_tokens\n",
    "\n",
    "# Apply cleaning\n",
    "dfUNSpeechComplete[['cleaned_tokens', 'tokens_clean_stemmed']] = dfUNSpeechComplete['text'].apply(text_cleaner).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d14f06981730091",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:48:39.266404Z",
     "start_time": "2025-07-24T15:48:39.258607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokens                  [On, my, way, to, the, Assembly, Hall, ,, I, w...\n",
       "tokens_clean            [way, assembly, hall, informed, supreme, state...\n",
       "tokens_clean_stemmed    [way, assembl, hall, inform, suprem, state, co...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the first row and two specific variables (columns)\n",
    "dfUNSpeechComplete.iloc[0][['tokens', 'tokens_clean', 'tokens_clean_stemmed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fbaadca1468ac058",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:50:56.224169Z",
     "start_time": "2025-07-24T15:50:56.217545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of tokens: 1057 \n",
      " length of clean tokens: 932 \n",
      " length of stemmed and clean tokens: 818 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"length of tokens:\", len(set(dfUNSpeechComplete.loc[0, 'tokens'])), \"\\n\",\n",
    "      \"length of clean tokens:\", len(set(dfUNSpeechComplete.loc[0, 'tokens_clean'])), \"\\n\",\n",
    "      \"length of stemmed and clean tokens:\", len(set(dfUNSpeechComplete.loc[0, 'tokens_clean_stemmed'])), \"\\n\",\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83805c3f4c376aad",
   "metadata": {},
   "source": [
    "**Lemmatization**\n",
    "- It takes one step further and try to transform a word in its roots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c14baec0c11ab2",
   "metadata": {},
   "source": [
    "**Example: Lemmatization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a36c8945c21f785",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T16:01:08.393467Z",
     "start_time": "2025-07-24T16:00:31.677907Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to clean and stem tokens\n",
    "def text_cleaner(text):\n",
    "    tokens = nltk.tokenize.word_tokenize(text)\n",
    "    cleaned_tokens = [word.lower() for word in tokens if word.lower() not in stop_words and word not in punctuations]\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in cleaned_tokens]\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in cleaned_tokens]\n",
    "    return cleaned_tokens, stemmed_tokens, lemmatized_tokens\n",
    "\n",
    "# Apply cleaning\n",
    "dfUNSpeechComplete[['cleaned_tokens', 'tokens_clean_stemmed', 'tokens_clean_lemmatized']] = dfUNSpeechComplete['text'].apply(text_cleaner).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9c91a275d0793292",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T16:01:27.926056Z",
     "start_time": "2025-07-24T16:01:27.917617Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokens                     [On, my, way, to, the, Assembly, Hall, ,, I, w...\n",
       "tokens_clean               [way, assembly, hall, informed, supreme, state...\n",
       "tokens_clean_stemmed       [way, assembl, hall, inform, suprem, state, co...\n",
       "tokens_clean_lemmatized    [way, assembly, hall, informed, supreme, state...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the first row and two specific variables (columns)\n",
    "dfUNSpeechComplete.iloc[0][['tokens', 'tokens_clean', 'tokens_clean_stemmed', 'tokens_clean_lemmatized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5a0d1c1b6f1b5e31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T16:02:39.755531Z",
     "start_time": "2025-07-24T16:02:39.749106Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of tokens: 1057 \n",
      " length of clean tokens: 932 \n",
      " length of stemmed and clean tokens: 818 \n",
      " length of lemmatized and clean tokens: 897 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"length of tokens:\", len(set(dfUNSpeechComplete.loc[0, 'tokens'])), \"\\n\",\n",
    "      \"length of clean tokens:\", len(set(dfUNSpeechComplete.loc[0, 'tokens_clean'])), \"\\n\",\n",
    "      \"length of stemmed and clean tokens:\", len(set(dfUNSpeechComplete.loc[0, 'tokens_clean_stemmed'])), \"\\n\",\n",
    "      \"length of lemmatized and clean tokens:\", len(set(dfUNSpeechComplete.loc[0, 'tokens_clean_lemmatized'])), \"\\n\",\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870bc01c1b86862f",
   "metadata": {},
   "source": [
    "### Exercise 1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b860451236f9585f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Points:\n",
    "    - You can do one thing in multiple ways.\n",
    "        - How do you decide which path you take:\n",
    "                - The most important factor is efficiency of your code: How fast your code can be run?"
   ],
   "id": "acd031ba7d6e32fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:03:47.351040Z",
     "start_time": "2025-07-24T15:03:47.345092Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "be4dc7afabe55964",
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "006212cd-97c2-4fbc-b511-54356e393f97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T14:13:57.888649Z",
     "start_time": "2025-07-24T14:13:57.884242Z"
    }
   },
   "source": [
    "from IPython.display import clear_output\n",
    "def countdown_timer(seconds):\n",
    "    for i in range(seconds, -1, -1):\n",
    "        clear_output(wait=True)\n",
    "        print(f\"⏳ Time remaining: {i} seconds\")\n",
    "        time.sleep(1)\n",
    "    print(\"✅ Time's up!\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "c8d6e645-cb93-42f0-bf6d-ae50cd649e9d",
   "metadata": {},
   "source": [
    "# Text and its features "
   ]
  },
  {
   "cell_type": "code",
   "id": "33d6a13f-1bf4-4a15-801f-4ac4afcb5279",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:47:39.386888Z",
     "start_time": "2025-07-24T15:47:39.381320Z"
    }
   },
   "source": [
    "import os\n",
    "import time\n",
    "import string\n",
    "import pandas as pd \n",
    "import nltk # this the basic and traditional package for text analysis in python \n",
    "import textstat # this the basic package for measuring linguistic features of a text"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:47:39.827380Z",
     "start_time": "2025-07-24T15:47:39.731224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Download necessary resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')"
   ],
   "id": "2b367627827aa25",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to F:\\Mahdi\\Dropbox\\Dropbox\\code\n",
      "[nltk_data]     \\courseTeach\\.venv\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:55:23.217605Z",
     "start_time": "2025-07-24T15:55:23.212681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize stemmer\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()"
   ],
   "id": "42e6de53bbdbe649",
   "outputs": [],
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "id": "48eea6e6-f4ac-497d-ae25-db9d198ac4a0",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "    A{Subject of study} --> B{Text}\n",
    "    B --> | influence | C[Content of Text]\n",
    "    B --> | influence | D[Linguistic Features of Text]\n",
    "```\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64438534-5622-42f9-ab56-0f69eb85e819",
   "metadata": {},
   "source": [
    "## 1.1. Meta data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfd1bfb-c654-454e-82b8-f2e4089a0037",
   "metadata": {},
   "source": [
    "Each text has three types of data that can be useful: \n",
    "\n",
    "- Metadata \n",
    "  - Any information about a text: author, type of text (speech, tweet,...), date of publication, language, etc.\n",
    "    - Sometimes metadata appears in text itself. \n",
    "    \n",
    "    \n",
    "- Textual data \n",
    "  - Linguistic features of text\n",
    "  - Content of text \n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823ac0ed-12b1-479d-9df4-4e3a0de50b0f",
   "metadata": {},
   "source": [
    "**Metadata**\n",
    "\n",
    "- When designing a project containing text analysis think carefully what kind of information you want to gather:\n",
    "  - You have to spend a huge amount of time to recover information that you did not code.\n",
    "\n",
    "- This is information beyond the text and its linguistic features. We refer to them as metadata, such as author, date, type, etc...\n",
    "- 3 ways to store and retrieve metadata\n",
    "  - Working with API\n",
    "  - Store in separate file and retrieve from it.  \n",
    "  - Store in the name of file and retrieve from it.\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff071cf2-b350-4e07-b340-4bdd965acb0a",
   "metadata": {},
   "source": [
    "### Exercise 1.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "715c04c2-6060-424f-8232-cf7b4b241aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Time remaining: 0 seconds\n",
      "✅ Time's up!\n"
     ]
    }
   ],
   "source": "countdown_timer(300)"
  },
  {
   "cell_type": "markdown",
   "id": "df5ec369-e98d-41fb-a18a-154a452c0ca0",
   "metadata": {},
   "source": [
    "'---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f72ffa-45ca-4bc3-8f04-943572132fc1",
   "metadata": {},
   "source": [
    "**Retrieve metadata from file names**"
   ]
  },
  {
   "cell_type": "code",
   "id": "e31173f8-2417-479f-a635-e4216b5954d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T14:14:06.631243Z",
     "start_time": "2025-07-24T14:14:06.119377Z"
    }
   },
   "source": [
    "# Step 1: read the files and store text and file names in a dictionary \n",
    "dictUNSpeech = {} # create an empty dictionary \n",
    "# The directory\n",
    "fileAddress1 = '../../corpusExample/unSpeeches2000_2010'\n",
    "# Open the file one by one - remember you need to tell python each single step - nothing here is automatic. \n",
    "# \n",
    "for file in os.listdir(fileAddress1):\n",
    "    with open(os.path.join(fileAddress1, file), 'r', encoding='utf-8', errors='replace') as textFile: \n",
    "        dictUNSpeech[file.replace('.txt', '')] =  textFile.read().lower()\n",
    "\n",
    "# convert the dictionary to a dataframe \n",
    "dfUNSpeech = pd.DataFrame(list(dictUNSpeech.items()), columns=[\"id\", \"text\"])\n",
    "\n",
    "dfUNSpeech[\"isoAlpha\"] = dfUNSpeech[\"id\"].str.split(\"_\", n=2,  expand=True)[0].astype('str')\n",
    "dfUNSpeech[\"session\"] = dfUNSpeech[\"id\"].str.split(\"_\", n=2, expand=True)[1].astype('int')\n",
    "dfUNSpeech[\"year\"] = dfUNSpeech[\"id\"].str.split(\"_\", n=2, expand=True)[2].astype('int')"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "fed1413f-63f6-4898-b85e-c1e001ed0d04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T14:14:11.420223Z",
     "start_time": "2025-07-24T14:14:11.383542Z"
    }
   },
   "source": [
    "dfUNSpeech.head(5)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            id                                               text isoAlpha  \\\n",
       "0  AFG_55_2000  On my way to the\\nAssembly Hall, I was informe...      AFG   \n",
       "1  AFG_56_2001  ﻿At the outset, on\\nbehalf of the Government o...      AFG   \n",
       "2  AFG_57_2002  ﻿Not very far from here stood\\ntwo towers that...      AFG   \n",
       "3  AFG_58_2003  ﻿There is no reality more\\noppressive than the...      AFG   \n",
       "4  AFG_59_2004  Nelson Mandela once\\ndescribed his countryís t...      AFG   \n",
       "\n",
       "   session  year  \n",
       "0       55  2000  \n",
       "1       56  2001  \n",
       "2       57  2002  \n",
       "3       58  2003  \n",
       "4       59  2004  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>isoAlpha</th>\n",
       "      <th>session</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG_55_2000</td>\n",
       "      <td>On my way to the\\nAssembly Hall, I was informe...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>55</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG_56_2001</td>\n",
       "      <td>﻿At the outset, on\\nbehalf of the Government o...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG_57_2002</td>\n",
       "      <td>﻿Not very far from here stood\\ntwo towers that...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>57</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG_58_2003</td>\n",
       "      <td>﻿There is no reality more\\noppressive than the...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>58</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG_59_2004</td>\n",
       "      <td>Nelson Mandela once\\ndescribed his countryís t...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>59</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "228594ee-127b-426d-8344-46936f69995f",
   "metadata": {},
   "source": [
    "**Example 2: Retreieve from Separate File** "
   ]
  },
  {
   "cell_type": "code",
   "id": "ea5f6d63-3165-452f-9670-e894eb16c9a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T14:15:52.204202Z",
     "start_time": "2025-07-24T14:15:51.466514Z"
    }
   },
   "source": [
    "fileAddress2 = '../../corpusExample/speakersSession.xlsx'\n",
    "speakerData = pd.read_excel(fileAddress2)\n",
    "dfUNSpeechComplete = dfUNSpeech.merge(speakerData, on=['year', 'isoAlpha'])"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "c49be6e3-3bab-4b30-ac22-eea3850f58bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T14:15:53.799931Z",
     "start_time": "2025-07-24T14:15:53.790034Z"
    }
   },
   "source": [
    "dfUNSpeechComplete.head(5)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            id                                               text isoAlpha  \\\n",
       "0  AFG_55_2000  On my way to the\\nAssembly Hall, I was informe...      AFG   \n",
       "1  AFG_56_2001  ﻿At the outset, on\\nbehalf of the Government o...      AFG   \n",
       "2  AFG_57_2002  ﻿Not very far from here stood\\ntwo towers that...      AFG   \n",
       "3  AFG_58_2003  ﻿There is no reality more\\noppressive than the...      AFG   \n",
       "4  AFG_59_2004  Nelson Mandela once\\ndescribed his countryís t...      AFG   \n",
       "\n",
       "   session  year  Session        cname        speakerName       post  \n",
       "0       55  2000       55  Afghanistan  Abdullah Abdullah        MFA  \n",
       "1       56  2001       56  Afghanistan      Ravan Farhâdi     UN_Rep  \n",
       "2       57  2002       57  Afghanistan       Hâmid Karzai  President  \n",
       "3       58  2003       58  Afghanistan       Hâmid Karzai  President  \n",
       "4       59  2004       59  Afghanistan   Mr. Hamid Karzai  President  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>isoAlpha</th>\n",
       "      <th>session</th>\n",
       "      <th>year</th>\n",
       "      <th>Session</th>\n",
       "      <th>cname</th>\n",
       "      <th>speakerName</th>\n",
       "      <th>post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG_55_2000</td>\n",
       "      <td>On my way to the\\nAssembly Hall, I was informe...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>55</td>\n",
       "      <td>2000</td>\n",
       "      <td>55</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Abdullah Abdullah</td>\n",
       "      <td>MFA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG_56_2001</td>\n",
       "      <td>﻿At the outset, on\\nbehalf of the Government o...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>56</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Ravan Farhâdi</td>\n",
       "      <td>UN_Rep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG_57_2002</td>\n",
       "      <td>﻿Not very far from here stood\\ntwo towers that...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>57</td>\n",
       "      <td>2002</td>\n",
       "      <td>57</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Hâmid Karzai</td>\n",
       "      <td>President</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG_58_2003</td>\n",
       "      <td>﻿There is no reality more\\noppressive than the...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>58</td>\n",
       "      <td>2003</td>\n",
       "      <td>58</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Hâmid Karzai</td>\n",
       "      <td>President</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG_59_2004</td>\n",
       "      <td>Nelson Mandela once\\ndescribed his countryís t...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>59</td>\n",
       "      <td>2004</td>\n",
       "      <td>59</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Mr. Hamid Karzai</td>\n",
       "      <td>President</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "d83b4c46-4258-46d5-bd86-2cdf5c57253e",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "**Some Abbreviation** \n",
    "- Prime Minister: PM \n",
    "- Deputy Prime Minister: DPM \n",
    "- Head of Government: HOG\n",
    "- Head of State: HOS\n",
    "- Minister for Foreign Affairs: MFA\n",
    "- UN Representative: UN_rep\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35e65cd-427d-4916-9a33-ec252a6faf02",
   "metadata": {},
   "source": [
    "**Example 3: working with API**"
   ]
  },
  {
   "cell_type": "code",
   "id": "51e06a5f-d057-453d-a4d8-3a47dd711d3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T14:15:57.840625Z",
     "start_time": "2025-07-24T14:15:57.837381Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e2e890f5-e80f-4af4-a844-87890bfdc674",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab14ecf-b143-4ee6-9eb3-32233a62426f",
   "metadata": {},
   "source": "### Exercise 1.2"
  },
  {
   "cell_type": "code",
   "id": "c3f83c7e-2d2c-4867-aa21-5f116de2eea1",
   "metadata": {},
   "source": "countdown_timer(300)",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mcountdown_timer\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m300\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[2], line 6\u001B[0m, in \u001B[0;36mcountdown_timer\u001B[1;34m(seconds)\u001B[0m\n\u001B[0;32m      4\u001B[0m     clear_output(wait\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m⏳ Time remaining: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m seconds\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 6\u001B[0m     \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m✅ Time\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms up!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "---"
   ],
   "id": "b7f5c741dab19afe"
  },
  {
   "cell_type": "markdown",
   "id": "b23aff61-b44c-4c75-9a0b-e5b14ef1b774",
   "metadata": {},
   "source": [
    "## 1.2. Linguistic Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72febbb8-d2c9-4644-9591-9de73cdc46c0",
   "metadata": {},
   "source": [
    "**How Does Linguistic Features help us?**\n",
    "Sometimes we do not need a complex method to achieve our goal. \n",
    "\n",
    "Simple measurements are useful. \n",
    "\n",
    "Some linguistic features:\n",
    "- Length of text\n",
    "- Number of sentences \n",
    "- Length of sentences \n",
    "- Complexity of text\n",
    "- ..."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "---"
   ],
   "id": "7cd8beac7a16e1e8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "aaaa**Example**",
   "id": "5fcdfa6baf5e26e"
  },
  {
   "cell_type": "code",
   "id": "c1a98b3a-dab5-4adf-9904-3ca8d594eb4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T14:16:02.927430Z",
     "start_time": "2025-07-24T14:16:02.690490Z"
    }
   },
   "source": [
    "# the length of each text \n",
    "dfUNSpeechComplete['word_count'] = dfUNSpeechComplete['text'].str.split().str.len()\n",
    "dfUNSpeechComplete"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               id                                               text isoAlpha  \\\n",
       "0     AFG_55_2000  On my way to the\\nAssembly Hall, I was informe...      AFG   \n",
       "1     AFG_56_2001  ﻿At the outset, on\\nbehalf of the Government o...      AFG   \n",
       "2     AFG_57_2002  ﻿Not very far from here stood\\ntwo towers that...      AFG   \n",
       "3     AFG_58_2003  ﻿There is no reality more\\noppressive than the...      AFG   \n",
       "4     AFG_59_2004  Nelson Mandela once\\ndescribed his countryís t...      AFG   \n",
       "...           ...                                                ...      ...   \n",
       "2072  ZWE_61_2006  Let me begin my statement \\nby echoing the sen...      ZWE   \n",
       "2073  ZWE_62_2007  Allow me to congratulate \\nMr. Kerim on his el...      ZWE   \n",
       "2074  ZWE_63_2008  I wish to begin by joining \\nthose who have co...      ZWE   \n",
       "2075  ZWE_64_2009  Let me begin by extending \\nour warmest congra...      ZWE   \n",
       "2076  ZWE_65_2010  Allow me once again to \\nextend to you, Sir, o...      ZWE   \n",
       "\n",
       "      session  year  Session        cname                speakerName  \\\n",
       "0          55  2000       55  Afghanistan          Abdullah Abdullah   \n",
       "1          56  2001       56  Afghanistan              Ravan Farhâdi   \n",
       "2          57  2002       57  Afghanistan               Hâmid Karzai   \n",
       "3          58  2003       58  Afghanistan               Hâmid Karzai   \n",
       "4          59  2004       59  Afghanistan           Mr. Hamid Karzai   \n",
       "...       ...   ...      ...          ...                        ...   \n",
       "2072       61  2006       61     Zimbabwe  Mr. Robert Gabriel Mugabe   \n",
       "2073       62  2007       62     Zimbabwe           Robert G. Mugabe   \n",
       "2074       63  2008       63     Zimbabwe              Robert Mugabe   \n",
       "2075       64  2009       64     Zimbabwe           Robert G. Mugabe   \n",
       "2076       65  2010       65     Zimbabwe           Robert G. Mugabe   \n",
       "\n",
       "           post  word_count  \n",
       "0           MFA        2873  \n",
       "1        UN_Rep        2073  \n",
       "2     President        1700  \n",
       "3     President        1617  \n",
       "4     President        1096  \n",
       "...         ...         ...  \n",
       "2072  President        2371  \n",
       "2073  President        2052  \n",
       "2074  President        1800  \n",
       "2075  President        1722  \n",
       "2076  President        1558  \n",
       "\n",
       "[2077 rows x 10 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>isoAlpha</th>\n",
       "      <th>session</th>\n",
       "      <th>year</th>\n",
       "      <th>Session</th>\n",
       "      <th>cname</th>\n",
       "      <th>speakerName</th>\n",
       "      <th>post</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG_55_2000</td>\n",
       "      <td>On my way to the\\nAssembly Hall, I was informe...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>55</td>\n",
       "      <td>2000</td>\n",
       "      <td>55</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Abdullah Abdullah</td>\n",
       "      <td>MFA</td>\n",
       "      <td>2873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG_56_2001</td>\n",
       "      <td>﻿At the outset, on\\nbehalf of the Government o...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>56</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Ravan Farhâdi</td>\n",
       "      <td>UN_Rep</td>\n",
       "      <td>2073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG_57_2002</td>\n",
       "      <td>﻿Not very far from here stood\\ntwo towers that...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>57</td>\n",
       "      <td>2002</td>\n",
       "      <td>57</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Hâmid Karzai</td>\n",
       "      <td>President</td>\n",
       "      <td>1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG_58_2003</td>\n",
       "      <td>﻿There is no reality more\\noppressive than the...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>58</td>\n",
       "      <td>2003</td>\n",
       "      <td>58</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Hâmid Karzai</td>\n",
       "      <td>President</td>\n",
       "      <td>1617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG_59_2004</td>\n",
       "      <td>Nelson Mandela once\\ndescribed his countryís t...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>59</td>\n",
       "      <td>2004</td>\n",
       "      <td>59</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Mr. Hamid Karzai</td>\n",
       "      <td>President</td>\n",
       "      <td>1096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>ZWE_61_2006</td>\n",
       "      <td>Let me begin my statement \\nby echoing the sen...</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>61</td>\n",
       "      <td>2006</td>\n",
       "      <td>61</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Mr. Robert Gabriel Mugabe</td>\n",
       "      <td>President</td>\n",
       "      <td>2371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>ZWE_62_2007</td>\n",
       "      <td>Allow me to congratulate \\nMr. Kerim on his el...</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>62</td>\n",
       "      <td>2007</td>\n",
       "      <td>62</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Robert G. Mugabe</td>\n",
       "      <td>President</td>\n",
       "      <td>2052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <td>ZWE_63_2008</td>\n",
       "      <td>I wish to begin by joining \\nthose who have co...</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>63</td>\n",
       "      <td>2008</td>\n",
       "      <td>63</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Robert Mugabe</td>\n",
       "      <td>President</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>ZWE_64_2009</td>\n",
       "      <td>Let me begin by extending \\nour warmest congra...</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>64</td>\n",
       "      <td>2009</td>\n",
       "      <td>64</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Robert G. Mugabe</td>\n",
       "      <td>President</td>\n",
       "      <td>1722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>ZWE_65_2010</td>\n",
       "      <td>Allow me once again to \\nextend to you, Sir, o...</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>65</td>\n",
       "      <td>2010</td>\n",
       "      <td>65</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Robert G. Mugabe</td>\n",
       "      <td>President</td>\n",
       "      <td>1558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2077 rows × 10 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "---"
   ],
   "id": "8abb5cd8da584dc1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Example: counting the number of sentences**",
   "id": "521aeba8c942e793"
  },
  {
   "cell_type": "code",
   "id": "cf46da03-ba4d-470b-894b-7e80bf3faae9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T14:29:54.947309Z",
     "start_time": "2025-07-24T14:29:53.041014Z"
    }
   },
   "source": [
    "# Apply sentence tokenizer\n",
    "dfUNSpeechComplete['sentence_count'] = dfUNSpeechComplete['text'].apply(lambda x: len(nltk.tokenize.sent_tokenize(x)))"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "b9ecb02a-2d0a-416c-9d31-857ba40b3e80",
   "metadata": {},
   "source": [
    "- You can count the number of sentences using spaCy as well. We will come to that later."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "---"
   ],
   "id": "b351f062e59a7a73"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Example: looking at the frequency of speeches from different officials**",
   "id": "f5b78ecd421e5009"
  },
  {
   "cell_type": "code",
   "id": "4adebe77-81bc-4d9d-90be-3bf8a0f864c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T14:30:44.046461Z",
     "start_time": "2025-07-24T14:30:44.038217Z"
    }
   },
   "source": [
    "dfUNSpeechComplete['post'].value_counts()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "post\n",
       "MFA            955\n",
       "President      533\n",
       "PM             221\n",
       "UN_Rep         187\n",
       "DPM            109\n",
       "V-President     34\n",
       "HOS             24\n",
       "HOG             14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "---"
   ],
   "id": "3571b4c889773050"
  },
  {
   "cell_type": "markdown",
   "id": "edb0514e-84f4-4582-a4c1-021b46132af7",
   "metadata": {},
   "source": [
    "**Features of Text that could be interesting:**\n",
    "- Length \n",
    "- Readability \n",
    "- Entropy\n",
    "- Lexical diversity\n",
    "- Tenses of verbs "
   ]
  },
  {
   "cell_type": "code",
   "id": "5147280a-6060-4375-bef4-7760d9c7ef5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T14:32:55.096955Z",
     "start_time": "2025-07-24T14:32:55.081569Z"
    }
   },
   "source": [
    "# Correct usage of textstat.flesch_reading_ease\n",
    "dfUNSpeechComplete['flesch_reading_ease'] = dfUNSpeechComplete['text'].apply(textstat.flesch_reading_ease)"
   ],
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'textstat' has no attribute 'flesch_reading_ease'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Correct usage of textstat.flesch_reading_ease\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m dfUNSpeechComplete[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mflesch_reading_ease\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m dfUNSpeechComplete[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[43mtextstat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflesch_reading_ease\u001B[49m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'textstat' has no attribute 'flesch_reading_ease'"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "---"
   ],
   "id": "2f19c167cc3d883f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Exercise 1.3",
   "id": "d816c04d65c91dbf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "countdown_timer(300)",
   "id": "39aedae03a3f2808"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "---"
   ],
   "id": "320aa5fa68d99e9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Tokenization**\n",
    " - The next step in analyzing text, is to break down the documents into elements that can be quantified.\n",
    "  - The basic element in each document is called *token*.\n",
    "  - Does token mean word? Not necessarily. But token usually corresponds to a word."
   ],
   "id": "cc3fba223045b50d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**NLTK**\n",
    "- In the good old days (almost 8 years ago), the package *NLTK* was the main package for doing basic NLP tasks.\n",
    "- Here we use it to break down our documents to words."
   ],
   "id": "de4d9a199a3df308"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Example: Tokenization**",
   "id": "2985baf66e7d216d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T14:46:44.317457Z",
     "start_time": "2025-07-24T14:46:28.290354Z"
    }
   },
   "cell_type": "code",
   "source": "dfUNSpeechComplete['tokens'] = dfUNSpeechComplete['text'].apply(nltk.tokenize.word_tokenize)",
   "id": "c8c5fb9021671a8d",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T14:46:47.888795Z",
     "start_time": "2025-07-24T14:46:47.874237Z"
    }
   },
   "cell_type": "code",
   "source": "dfUNSpeechComplete",
   "id": "dc22b90aca4a6b03",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               id                                               text isoAlpha  \\\n",
       "0     AFG_55_2000  On my way to the\\nAssembly Hall, I was informe...      AFG   \n",
       "1     AFG_56_2001  ﻿At the outset, on\\nbehalf of the Government o...      AFG   \n",
       "2     AFG_57_2002  ﻿Not very far from here stood\\ntwo towers that...      AFG   \n",
       "3     AFG_58_2003  ﻿There is no reality more\\noppressive than the...      AFG   \n",
       "4     AFG_59_2004  Nelson Mandela once\\ndescribed his countryís t...      AFG   \n",
       "...           ...                                                ...      ...   \n",
       "2072  ZWE_61_2006  Let me begin my statement \\nby echoing the sen...      ZWE   \n",
       "2073  ZWE_62_2007  Allow me to congratulate \\nMr. Kerim on his el...      ZWE   \n",
       "2074  ZWE_63_2008  I wish to begin by joining \\nthose who have co...      ZWE   \n",
       "2075  ZWE_64_2009  Let me begin by extending \\nour warmest congra...      ZWE   \n",
       "2076  ZWE_65_2010  Allow me once again to \\nextend to you, Sir, o...      ZWE   \n",
       "\n",
       "      session  year  Session        cname                speakerName  \\\n",
       "0          55  2000       55  Afghanistan          Abdullah Abdullah   \n",
       "1          56  2001       56  Afghanistan              Ravan Farhâdi   \n",
       "2          57  2002       57  Afghanistan               Hâmid Karzai   \n",
       "3          58  2003       58  Afghanistan               Hâmid Karzai   \n",
       "4          59  2004       59  Afghanistan           Mr. Hamid Karzai   \n",
       "...       ...   ...      ...          ...                        ...   \n",
       "2072       61  2006       61     Zimbabwe  Mr. Robert Gabriel Mugabe   \n",
       "2073       62  2007       62     Zimbabwe           Robert G. Mugabe   \n",
       "2074       63  2008       63     Zimbabwe              Robert Mugabe   \n",
       "2075       64  2009       64     Zimbabwe           Robert G. Mugabe   \n",
       "2076       65  2010       65     Zimbabwe           Robert G. Mugabe   \n",
       "\n",
       "           post  word_count  sentence_count  \\\n",
       "0           MFA        2873              67   \n",
       "1        UN_Rep        2073              81   \n",
       "2     President        1700              62   \n",
       "3     President        1617              83   \n",
       "4     President        1096              56   \n",
       "...         ...         ...             ...   \n",
       "2072  President        2371             100   \n",
       "2073  President        2052             121   \n",
       "2074  President        1800              65   \n",
       "2075  President        1722              63   \n",
       "2076  President        1558              68   \n",
       "\n",
       "                                                 tokens  \n",
       "0     [On, my, way, to, the, Assembly, Hall, ,, I, w...  \n",
       "1     [﻿At, the, outset, ,, on, behalf, of, the, Gov...  \n",
       "2     [﻿Not, very, far, from, here, stood, two, towe...  \n",
       "3     [﻿There, is, no, reality, more, oppressive, th...  \n",
       "4     [Nelson, Mandela, once, described, his, countr...  \n",
       "...                                                 ...  \n",
       "2072  [Let, me, begin, my, statement, by, echoing, t...  \n",
       "2073  [Allow, me, to, congratulate, Mr., Kerim, on, ...  \n",
       "2074  [I, wish, to, begin, by, joining, those, who, ...  \n",
       "2075  [Let, me, begin, by, extending, our, warmest, ...  \n",
       "2076  [Allow, me, once, again, to, extend, to, you, ...  \n",
       "\n",
       "[2077 rows x 12 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>isoAlpha</th>\n",
       "      <th>session</th>\n",
       "      <th>year</th>\n",
       "      <th>Session</th>\n",
       "      <th>cname</th>\n",
       "      <th>speakerName</th>\n",
       "      <th>post</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG_55_2000</td>\n",
       "      <td>On my way to the\\nAssembly Hall, I was informe...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>55</td>\n",
       "      <td>2000</td>\n",
       "      <td>55</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Abdullah Abdullah</td>\n",
       "      <td>MFA</td>\n",
       "      <td>2873</td>\n",
       "      <td>67</td>\n",
       "      <td>[On, my, way, to, the, Assembly, Hall, ,, I, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG_56_2001</td>\n",
       "      <td>﻿At the outset, on\\nbehalf of the Government o...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>56</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Ravan Farhâdi</td>\n",
       "      <td>UN_Rep</td>\n",
       "      <td>2073</td>\n",
       "      <td>81</td>\n",
       "      <td>[﻿At, the, outset, ,, on, behalf, of, the, Gov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG_57_2002</td>\n",
       "      <td>﻿Not very far from here stood\\ntwo towers that...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>57</td>\n",
       "      <td>2002</td>\n",
       "      <td>57</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Hâmid Karzai</td>\n",
       "      <td>President</td>\n",
       "      <td>1700</td>\n",
       "      <td>62</td>\n",
       "      <td>[﻿Not, very, far, from, here, stood, two, towe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG_58_2003</td>\n",
       "      <td>﻿There is no reality more\\noppressive than the...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>58</td>\n",
       "      <td>2003</td>\n",
       "      <td>58</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Hâmid Karzai</td>\n",
       "      <td>President</td>\n",
       "      <td>1617</td>\n",
       "      <td>83</td>\n",
       "      <td>[﻿There, is, no, reality, more, oppressive, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG_59_2004</td>\n",
       "      <td>Nelson Mandela once\\ndescribed his countryís t...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>59</td>\n",
       "      <td>2004</td>\n",
       "      <td>59</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Mr. Hamid Karzai</td>\n",
       "      <td>President</td>\n",
       "      <td>1096</td>\n",
       "      <td>56</td>\n",
       "      <td>[Nelson, Mandela, once, described, his, countr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>ZWE_61_2006</td>\n",
       "      <td>Let me begin my statement \\nby echoing the sen...</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>61</td>\n",
       "      <td>2006</td>\n",
       "      <td>61</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Mr. Robert Gabriel Mugabe</td>\n",
       "      <td>President</td>\n",
       "      <td>2371</td>\n",
       "      <td>100</td>\n",
       "      <td>[Let, me, begin, my, statement, by, echoing, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>ZWE_62_2007</td>\n",
       "      <td>Allow me to congratulate \\nMr. Kerim on his el...</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>62</td>\n",
       "      <td>2007</td>\n",
       "      <td>62</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Robert G. Mugabe</td>\n",
       "      <td>President</td>\n",
       "      <td>2052</td>\n",
       "      <td>121</td>\n",
       "      <td>[Allow, me, to, congratulate, Mr., Kerim, on, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <td>ZWE_63_2008</td>\n",
       "      <td>I wish to begin by joining \\nthose who have co...</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>63</td>\n",
       "      <td>2008</td>\n",
       "      <td>63</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Robert Mugabe</td>\n",
       "      <td>President</td>\n",
       "      <td>1800</td>\n",
       "      <td>65</td>\n",
       "      <td>[I, wish, to, begin, by, joining, those, who, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>ZWE_64_2009</td>\n",
       "      <td>Let me begin by extending \\nour warmest congra...</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>64</td>\n",
       "      <td>2009</td>\n",
       "      <td>64</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Robert G. Mugabe</td>\n",
       "      <td>President</td>\n",
       "      <td>1722</td>\n",
       "      <td>63</td>\n",
       "      <td>[Let, me, begin, by, extending, our, warmest, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>ZWE_65_2010</td>\n",
       "      <td>Allow me once again to \\nextend to you, Sir, o...</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>65</td>\n",
       "      <td>2010</td>\n",
       "      <td>65</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Robert G. Mugabe</td>\n",
       "      <td>President</td>\n",
       "      <td>1558</td>\n",
       "      <td>68</td>\n",
       "      <td>[Allow, me, once, again, to, extend, to, you, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2077 rows × 12 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**spaCy**\n",
    "- You can use *spaCy* to do tokenization for you.\n",
    "- More efficient, more accurate\n",
    "- We come back to spaCy in our last session."
   ],
   "id": "dd4355ebf82f040f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T14:59:29.607411Z",
     "start_time": "2025-07-24T14:59:29.603391Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d1fc52345149ce60",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "---"
   ],
   "id": "df8ec13fb2ce3e36"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Exersice 1.4",
   "id": "32c00253b0ba1e30"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "countdown_timer(300)",
   "id": "14b9eb4b18d22ed7",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mcountdown_timer\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m300\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[2], line 6\u001B[0m, in \u001B[0;36mcountdown_timer\u001B[1;34m(seconds)\u001B[0m\n\u001B[0;32m      4\u001B[0m     clear_output(wait\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m⏳ Time remaining: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m seconds\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 6\u001B[0m     \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m✅ Time\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms up!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "---"
   ],
   "id": "7f8e3ecbc7554c9f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Removing**\n",
    "- Not all tokens are meanigful.\n",
    "- We want to drop those tokens that do not carry any meaning.\n",
    "- The most obvious ones are punctuations and stopwords:\n",
    "    - Stopwords: Pronomens, articles, prepositions"
   ],
   "id": "71983c96e2f0974b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Example: removing words that are not meaningful.**",
   "id": "a41719206e8dc4a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:05:50.665914Z",
     "start_time": "2025-07-24T15:05:50.386408Z"
    }
   },
   "cell_type": "code",
   "source": "nltk.download('stopwords')",
   "id": "16c3310fc77f27bf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to F:\\Mahdi\\Dropbox\\Dropbox\\\n",
      "[nltk_data]     code\\courseTeach\\.venv\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:05:52.347328Z",
     "start_time": "2025-07-24T15:05:52.338389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# English stopwords and punctuation\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "punctuations = set(string.punctuation)"
   ],
   "id": "ac6767d1e2155dc1",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:07:43.096810Z",
     "start_time": "2025-07-24T15:07:25.917264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to clean tokens\n",
    "def text_cleaner(text):\n",
    "    tokens = nltk.tokenize.word_tokenize(text)\n",
    "    return [word.lower() for word in tokens if word.lower() not in stop_words and word not in punctuations]\n",
    "\n",
    "# Apply cleaning\n",
    "dfUNSpeechComplete['tokens_clean'] = dfUNSpeechComplete['text'].apply(text_cleaner)"
   ],
   "id": "6a1ce8253f6e77e8",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:09:10.021428Z",
     "start_time": "2025-07-24T15:09:10.013320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Access the first row and two specific variables (columns)\n",
    "dfUNSpeechComplete.iloc[0][['tokens', 'tokens_clean']]"
   ],
   "id": "bc2f8c2f832b8e21",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokens          [On, my, way, to, the, Assembly, Hall, ,, I, w...\n",
       "tokens_clean    [way, assembly, hall, informed, supreme, state...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:13:13.298154Z",
     "start_time": "2025-07-24T15:13:13.292509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"length of tokens:\", len(dfUNSpeechComplete.loc[0, 'tokens']), \"\\n\",\n",
    "      \"length of clean tokens:\", len(dfUNSpeechComplete.loc[0, 'tokens_clean'])\n",
    "      )"
   ],
   "id": "988ce20f493015c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of tokens: 3173 \n",
      " length of clean tokens: 1622\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:50:13.422133Z",
     "start_time": "2025-07-24T15:50:13.416166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"length of tokens:\", len(set(dfUNSpeechComplete.loc[0, 'tokens'])), \"\\n\",\n",
    "      \"length of clean tokens:\", len(set(dfUNSpeechComplete.loc[0, 'tokens_clean']))\n",
    "      )"
   ],
   "id": "84f2367845a129b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of tokens: 1057 \n",
      " length of clean tokens: 932\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "---"
   ],
   "id": "14339c679811d40e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Exercise 1.5",
   "id": "34184c6294a8593"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T14:27:18.573524Z",
     "start_time": "2025-07-24T14:27:18.569818Z"
    }
   },
   "cell_type": "code",
   "source": "countdown_timer(300)",
   "id": "3ae81b42a1c7df30",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "---"
   ],
   "id": "1b59185631bcd52a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Words that are similar but not identical**\n",
    "- What is the difference between run, running and runs?\n",
    "    - There is no difference in their meaning.\n",
    "    - But from the perspective of tokenizer they are separate words.\n",
    "- Solution to the problem:\n",
    "    - Stemming\n",
    "    - Lemmatization"
   ],
   "id": "c4bf320a173cf145"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Stemming**\n",
    "- We cut a few alphabets at the end of words:\n",
    "    - run, run, run: we will have the same words 3 times instead of 3 different words just one time."
   ],
   "id": "bd6b4a0682ccf18"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Example: Stemming**",
   "id": "cd88b2d34b57bcdb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:59:06.604950Z",
     "start_time": "2025-07-24T15:58:36.270702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to clean and stem tokens\n",
    "def text_cleaner(text):\n",
    "    tokens = nltk.tokenize.word_tokenize(text)\n",
    "    cleaned_tokens = [word.lower() for word in tokens if word.lower() not in stop_words and word not in punctuations]\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in cleaned_tokens]\n",
    "    return cleaned_tokens, stemmed_tokens\n",
    "\n",
    "# Apply cleaning\n",
    "dfUNSpeechComplete[['cleaned_tokens', 'tokens_clean_stemmed']] = dfUNSpeechComplete['text'].apply(text_cleaner).apply(pd.Series)"
   ],
   "id": "790eaf143f62d61e",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_3656\\3496200320.py\u001B[0m in \u001B[0;36m?\u001B[1;34m()\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0mstemmed_tokens\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mstemmer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtoken\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mtoken\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mcleaned_tokens\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mcleaned_tokens\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstemmed_tokens\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;31m# Apply cleaning\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m \u001B[0mdfUNSpeechComplete\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'cleaned_tokens'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'tokens_clean_stemmed'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdfUNSpeechComplete\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'text'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext_cleaner\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mF:\\Mahdi\\Dropbox\\Dropbox\\code\\courseTeach\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, key, value)\u001B[0m\n\u001B[0;32m   4295\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4296\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mDataFrame\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"ndim\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m2\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4297\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_setitem_frame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4298\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mSeries\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mIndex\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 4299\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_setitem_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   4300\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mDataFrame\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4301\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_set_item_frame_value\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4302\u001B[0m         elif (\n",
      "\u001B[1;32mF:\\Mahdi\\Dropbox\\Dropbox\\code\\courseTeach\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, key, value)\u001B[0m\n\u001B[0;32m   4354\u001B[0m                 \u001B[0mvalue\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4355\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_setitem_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4356\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4357\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 4358\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iset_not_inplace\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mF:\\Mahdi\\Dropbox\\Dropbox\\code\\courseTeach\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, key, value)\u001B[0m\n\u001B[0;32m   4373\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mobj\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4374\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4375\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_unique\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4376\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 4377\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Columns must be same length as key\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   4378\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4379\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcol\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4380\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mcol\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0migetitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Columns must be same length as key"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:48:39.266404Z",
     "start_time": "2025-07-24T15:48:39.258607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Access the first row and two specific variables (columns)\n",
    "dfUNSpeechComplete.iloc[0][['tokens', 'tokens_clean', 'tokens_clean_stemmed']]"
   ],
   "id": "2d14f06981730091",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokens                  [On, my, way, to, the, Assembly, Hall, ,, I, w...\n",
       "tokens_clean            [way, assembly, hall, informed, supreme, state...\n",
       "tokens_clean_stemmed    [way, assembl, hall, inform, suprem, state, co...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:50:56.224169Z",
     "start_time": "2025-07-24T15:50:56.217545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"length of tokens:\", len(set(dfUNSpeechComplete.loc[0, 'tokens'])), \"\\n\",\n",
    "      \"length of clean tokens:\", len(set(dfUNSpeechComplete.loc[0, 'tokens_clean'])), \"\\n\",\n",
    "      \"length of stemmed and clean tokens:\", len(set(dfUNSpeechComplete.loc[0, 'tokens_clean_stemmed'])), \"\\n\",\n",
    "      )"
   ],
   "id": "fbaadca1468ac058",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of tokens: 1057 \n",
      " length of clean tokens: 932 \n",
      " length of stemmed and clean tokens: 818 \n",
      "\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Lemmatization**\n",
    "- It takes one step further and try to transform a word in its roots"
   ],
   "id": "83805c3f4c376aad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Example: Lemmatization**",
   "id": "c5c14baec0c11ab2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T16:01:08.393467Z",
     "start_time": "2025-07-24T16:00:31.677907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to clean and stem tokens\n",
    "def text_cleaner(text):\n",
    "    tokens = nltk.tokenize.word_tokenize(text)\n",
    "    cleaned_tokens = [word.lower() for word in tokens if word.lower() not in stop_words and word not in punctuations]\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in cleaned_tokens]\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in cleaned_tokens]\n",
    "    return cleaned_tokens, stemmed_tokens, lemmatized_tokens\n",
    "\n",
    "# Apply cleaning\n",
    "dfUNSpeechComplete[['cleaned_tokens', 'tokens_clean_stemmed', 'tokens_clean_lemmatized']] = dfUNSpeechComplete['text'].apply(text_cleaner).apply(pd.Series)"
   ],
   "id": "2a36c8945c21f785",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T16:01:27.926056Z",
     "start_time": "2025-07-24T16:01:27.917617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Access the first row and two specific variables (columns)\n",
    "dfUNSpeechComplete.iloc[0][['tokens', 'tokens_clean', 'tokens_clean_stemmed', 'tokens_clean_lemmatized']]"
   ],
   "id": "9c91a275d0793292",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokens                     [On, my, way, to, the, Assembly, Hall, ,, I, w...\n",
       "tokens_clean               [way, assembly, hall, informed, supreme, state...\n",
       "tokens_clean_stemmed       [way, assembl, hall, inform, suprem, state, co...\n",
       "tokens_clean_lemmatized    [way, assembly, hall, informed, supreme, state...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T16:02:39.755531Z",
     "start_time": "2025-07-24T16:02:39.749106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"length of tokens:\", len(set(dfUNSpeechComplete.loc[0, 'tokens'])), \"\\n\",\n",
    "      \"length of clean tokens:\", len(set(dfUNSpeechComplete.loc[0, 'tokens_clean'])), \"\\n\",\n",
    "      \"length of stemmed and clean tokens:\", len(set(dfUNSpeechComplete.loc[0, 'tokens_clean_stemmed'])), \"\\n\",\n",
    "      \"length of lemmatized and clean tokens:\", len(set(dfUNSpeechComplete.loc[0, 'tokens_clean_lemmatized'])), \"\\n\",\n",
    "      )"
   ],
   "id": "5a0d1c1b6f1b5e31",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of tokens: 1057 \n",
      " length of clean tokens: 932 \n",
      " length of stemmed and clean tokens: 818 \n",
      " length of lemmatized and clean tokens: 897 \n",
      "\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Exercise 1.6",
   "id": "870bc01c1b86862f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

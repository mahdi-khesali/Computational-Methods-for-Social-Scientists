{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0ca8171-9d33-4f4c-bf66-970bd6548648",
   "metadata": {},
   "source": [
    "# Session 2: Bag of Words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eec081c0-8b46-4fc4-a93b-47ba96498f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d69844df-9614-463b-86f5-241520963642",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bax1408\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "057d9065-6962-44ec-b35a-a453db11ac10",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "punctuations = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f56259-68a2-4942-9fac-7736d9e6ff21",
   "metadata": {},
   "source": [
    "## Part 2: Bag of words representation of a text "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dc96c7-1b90-47bf-a26d-f257f682ce77",
   "metadata": {},
   "source": [
    "We need to represent words in numbers. \n",
    "- Bag of words \n",
    "- Embedding \n",
    "\n",
    "The simplest approach is to count the number of time a word appears in each document. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e853a9-d35f-4317-97d6-31332d7db6d1",
   "metadata": {},
   "source": [
    "**Steps** \n",
    "1. Read the document\n",
    "2. convert all words to lowercase. \n",
    "3. Remove punctuation. \n",
    "4. Remove stop words \n",
    "5. Create equivalence class\n",
    "6. Filter by Frequency \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eaff9f-9703-4783-befe-9408a4f93841",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dc5b6f-c863-4eea-88a9-d7ec9d5d96de",
   "metadata": {},
   "source": [
    "**Step 1 and 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e622c3b-e19e-43b9-82f1-982987bbf261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the documents \n",
    "# Step 1: read the files and store text and file names in a dictionary \n",
    "dictUNSpeech = {} # create an empty dictionary \n",
    "# The directory\n",
    "fileAddress1 = '../../corpusExample/unSpeeches2000_2010'\n",
    "# Open the file one by one - remember you need to tell python each single step - nothing here is automatic. \n",
    "# \n",
    "for file in os.listdir(fileAddress1):\n",
    "    with open(os.path.join(fileAddress1, file), 'r', encoding='utf-8', errors='replace') as textFile: \n",
    "        dictUNSpeech[file.replace('.txt', '')] =  textFile.read()\n",
    "\n",
    "# convert the dictionary to a dataframe \n",
    "dfUNSpeech = pd.DataFrame(list(dictUNSpeech.items()), columns=[\"id\", \"text\"])\n",
    "\n",
    "dfUNSpeech[\"isoAlpha\"] = dfUNSpeech[\"id\"].str.split(\"_\", n=2,  expand=True)[0].astype('str')\n",
    "dfUNSpeech[\"session\"] = dfUNSpeech[\"id\"].str.split(\"_\", n=2, expand=True)[1].astype('int')\n",
    "dfUNSpeech[\"year\"] = dfUNSpeech[\"id\"].str.split(\"_\", n=2, expand=True)[2].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02fcc939-ef1d-405e-ada3-8e9e3be89e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>isoAlpha</th>\n",
       "      <th>session</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG_55_2000</td>\n",
       "      <td>On my way to the\\nAssembly Hall, I was informe...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>55</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG_56_2001</td>\n",
       "      <td>﻿At the outset, on\\nbehalf of the Government o...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG_57_2002</td>\n",
       "      <td>﻿Not very far from here stood\\ntwo towers that...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>57</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG_58_2003</td>\n",
       "      <td>﻿There is no reality more\\noppressive than the...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>58</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG_59_2004</td>\n",
       "      <td>Nelson Mandela once\\ndescribed his countryís t...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>59</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <td>ZWE_61_2006</td>\n",
       "      <td>Let me begin my statement \\nby echoing the sen...</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>61</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>ZWE_62_2007</td>\n",
       "      <td>Allow me to congratulate \\nMr. Kerim on his el...</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>62</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>ZWE_63_2008</td>\n",
       "      <td>I wish to begin by joining \\nthose who have co...</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>63</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>ZWE_64_2009</td>\n",
       "      <td>Let me begin by extending \\nour warmest congra...</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>64</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>ZWE_65_2010</td>\n",
       "      <td>Allow me once again to \\nextend to you, Sir, o...</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>65</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2079 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                               text isoAlpha  \\\n",
       "0     AFG_55_2000  On my way to the\\nAssembly Hall, I was informe...      AFG   \n",
       "1     AFG_56_2001  ﻿At the outset, on\\nbehalf of the Government o...      AFG   \n",
       "2     AFG_57_2002  ﻿Not very far from here stood\\ntwo towers that...      AFG   \n",
       "3     AFG_58_2003  ﻿There is no reality more\\noppressive than the...      AFG   \n",
       "4     AFG_59_2004  Nelson Mandela once\\ndescribed his countryís t...      AFG   \n",
       "...           ...                                                ...      ...   \n",
       "2074  ZWE_61_2006  Let me begin my statement \\nby echoing the sen...      ZWE   \n",
       "2075  ZWE_62_2007  Allow me to congratulate \\nMr. Kerim on his el...      ZWE   \n",
       "2076  ZWE_63_2008  I wish to begin by joining \\nthose who have co...      ZWE   \n",
       "2077  ZWE_64_2009  Let me begin by extending \\nour warmest congra...      ZWE   \n",
       "2078  ZWE_65_2010  Allow me once again to \\nextend to you, Sir, o...      ZWE   \n",
       "\n",
       "      session  year  \n",
       "0          55  2000  \n",
       "1          56  2001  \n",
       "2          57  2002  \n",
       "3          58  2003  \n",
       "4          59  2004  \n",
       "...       ...   ...  \n",
       "2074       61  2006  \n",
       "2075       62  2007  \n",
       "2076       63  2008  \n",
       "2077       64  2009  \n",
       "2078       65  2010  \n",
       "\n",
       "[2079 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfUNSpeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9263817e-3f9e-4282-8a1a-40690de6343e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>000</th>\n",
       "      <th>001</th>\n",
       "      <th>005</th>\n",
       "      <th>01</th>\n",
       "      <th>020</th>\n",
       "      <th>04</th>\n",
       "      <th>041</th>\n",
       "      <th>043</th>\n",
       "      <th>05</th>\n",
       "      <th>...</th>\n",
       "      <th>ìstandards</th>\n",
       "      <th>ìwe</th>\n",
       "      <th>île</th>\n",
       "      <th>œi</th>\n",
       "      <th>œone</th>\n",
       "      <th>œour</th>\n",
       "      <th>œresponsibility</th>\n",
       "      <th>œrightâ</th>\n",
       "      <th>œwith</th>\n",
       "      <th>štampar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG_55_2000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG_56_2001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG_57_2002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG_58_2003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG_59_2004</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <td>ZWE_61_2006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>ZWE_62_2007</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>ZWE_63_2008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>ZWE_64_2009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>ZWE_65_2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2079 rows × 27832 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  000  001  005  01  020  04  041  043  05  ...  ìstandards  \\\n",
       "0     AFG_55_2000    3    0    0   0    0   0    0    0   0  ...           0   \n",
       "1     AFG_56_2001    0    0    0   0    0   0    0    0   0  ...           0   \n",
       "2     AFG_57_2002    0    0    0   0    0   0    0    0   0  ...           0   \n",
       "3     AFG_58_2003    0    0    0   0    0   0    0    0   0  ...           0   \n",
       "4     AFG_59_2004    2    0    0   0    0   0    0    0   0  ...           0   \n",
       "...           ...  ...  ...  ...  ..  ...  ..  ...  ...  ..  ...         ...   \n",
       "2074  ZWE_61_2006    0    0    0   0    0   0    0    0   0  ...           0   \n",
       "2075  ZWE_62_2007    2    0    0   0    0   0    0    0   0  ...           0   \n",
       "2076  ZWE_63_2008    0    0    0   0    0   0    0    0   0  ...           0   \n",
       "2077  ZWE_64_2009    0    0    0   0    0   0    0    0   0  ...           0   \n",
       "2078  ZWE_65_2010    0    0    0   0    0   0    0    0   0  ...           0   \n",
       "\n",
       "      ìwe  île  œi  œone  œour  œresponsibility  œrightâ  œwith  štampar  \n",
       "0       0    0   0     0     0                0        0      0        0  \n",
       "1       0    0   0     0     0                0        0      0        0  \n",
       "2       0    0   0     0     0                0        0      0        0  \n",
       "3       0    0   0     0     0                0        0      0        0  \n",
       "4       0    0   0     0     0                0        0      0        0  \n",
       "...   ...  ...  ..   ...   ...              ...      ...    ...      ...  \n",
       "2074    0    0   0     0     0                0        0      0        0  \n",
       "2075    0    0   1     0     0                0        0      1        0  \n",
       "2076    0    0   0     0     0                0        0      0        0  \n",
       "2077    0    0   0     0     0                0        0      0        0  \n",
       "2078    0    0   0     0     0                0        0      0        0  \n",
       "\n",
       "[2079 rows x 27832 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "dtm = vectorizer.fit_transform(dfUNSpeech['text'])   # returns a sparse matrix\n",
    "# Step 4: Convert to DataFrame\n",
    "dfDTM = pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "dfDTM[\"id\"] = dfUNSpeech[\"id\"]\n",
    "# Optional: move 'id' column to the front\n",
    "cols = dfDTM.columns.tolist()\n",
    "cols = [cols[-1]] + cols[:-1]\n",
    "dfDTM = dfDTM[cols]\n",
    "dfDTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940ea7fc-e9b0-402f-a418-ea8275bc4e9a",
   "metadata": {},
   "source": [
    "- This is quite messy and not useful.\n",
    "    - To solve these problems, we develop a preprocessor function step by step.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b95955b4-b446-468b-b1f5-1468eeb16f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21b4a521-18af-4bd9-a59f-31f41bd7f904",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'tokens' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# === Step 2: Vectorize using lemmatization ===\u001b[39;00m\n\u001b[0;32m     10\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m CountVectorizer(analyzer\u001b[38;5;241m=\u001b[39mcustom_preprocessor)\n\u001b[1;32m---> 11\u001b[0m dtm \u001b[38;5;241m=\u001b[39m \u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdfUNSpeech\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# === Step 3: Create document-term matrix ===\u001b[39;00m\n\u001b[0;32m     14\u001b[0m dfDTM \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(dtm\u001b[38;5;241m.\u001b[39mtoarray(), columns\u001b[38;5;241m=\u001b[39mvectorizer\u001b[38;5;241m.\u001b[39mget_feature_names_out())\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1376\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1368\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1369\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1370\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1371\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1372\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1373\u001b[0m             )\n\u001b[0;32m   1374\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1376\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1379\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1263\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[0;32m   1262\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1263\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1264\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1265\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:101\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m     99\u001b[0m     doc \u001b[38;5;241m=\u001b[39m decoder(doc)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m analyzer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 101\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43manalyzer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m preprocessor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[30], line 5\u001b[0m, in \u001b[0;36mcustom_preprocessor\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcustom_preprocessor\u001b[39m(text):\n\u001b[0;32m      3\u001b[0m     text \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m# removing digits \u001b[39;00m\n\u001b[0;32m      4\u001b[0m                   text\u001b[38;5;241m.\u001b[39mlower(), \u001b[38;5;66;03m# lowering the case \u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m                   tokens \u001b[38;5;241m=\u001b[39m [token \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtokens\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m token\u001b[38;5;241m.\u001b[39misalpha() \u001b[38;5;129;01mand\u001b[39;00m token \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stop_words \u001b[38;5;129;01mand\u001b[39;00m token \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m punctuations] \u001b[38;5;66;03m# Remove punctuation, stopwords, and non-alphabetic tokens\u001b[39;00m\n\u001b[0;32m      6\u001b[0m                  )\n\u001b[0;32m      7\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mtokenize\u001b[38;5;241m.\u001b[39mword_tokenize(text)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokens\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'tokens' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# Define custom analyzer for CountVectorizer\n",
    "def custom_preprocessor(text):\n",
    "    text = re.sub(r'\\d+', '', # removing digits \n",
    "                  text.lower(), # lowering the case \n",
    "                  tokens = [token for token in tokens if token.isalpha() and token not in stop_words and token not in punctuations] # Remove punctuation, stopwords, and non-alphabetic tokens\n",
    "                 )\n",
    "    tokens = nltk.tokenize.word_tokenize(text)\n",
    "    return tokens\n",
    "# === Step 2: Vectorize using lemmatization ===\n",
    "vectorizer = CountVectorizer(analyzer=custom_preprocessor)\n",
    "dtm = vectorizer.fit_transform(dfUNSpeech[\"text\"])\n",
    "\n",
    "# === Step 3: Create document-term matrix ===\n",
    "dfDTM = pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "dfDTM[\"id\"] = dfUNSpeech[\"id\"]\n",
    "dfDTM = dfDTM[[\"id\"] + dfDTM.columns[:-1].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa05b1f8-d53e-46d1-bc89-fd2f3256059d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>!</th>\n",
       "      <th>$</th>\n",
       "      <th>&amp;</th>\n",
       "      <th>'</th>\n",
       "      <th>''</th>\n",
       "      <th>'agenda</th>\n",
       "      <th>'bulgaria</th>\n",
       "      <th>'despite</th>\n",
       "      <th>'enemy</th>\n",
       "      <th>...</th>\n",
       "      <th>﻿to</th>\n",
       "      <th>﻿today</th>\n",
       "      <th>﻿trinidad</th>\n",
       "      <th>﻿twenty-four</th>\n",
       "      <th>﻿two</th>\n",
       "      <th>﻿uruguay</th>\n",
       "      <th>﻿we</th>\n",
       "      <th>﻿yesterday</th>\n",
       "      <th>﻿you</th>\n",
       "      <th>﻿your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG_55_2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG_56_2001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG_57_2002</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG_58_2003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG_59_2004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <td>ZWE_61_2006</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>ZWE_62_2007</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>ZWE_63_2008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>ZWE_64_2009</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>ZWE_65_2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2079 rows × 31112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  !  $  &  '  ''  'agenda  'bulgaria  'despite  'enemy  ...  \\\n",
       "0     AFG_55_2000  0  0  0  0   0        0          0         0       0  ...   \n",
       "1     AFG_56_2001  0  0  0  0   0        0          0         0       0  ...   \n",
       "2     AFG_57_2002  0  1  0  0   0        0          0         0       0  ...   \n",
       "3     AFG_58_2003  0  0  0  0   0        0          0         0       0  ...   \n",
       "4     AFG_59_2004  0  0  0  0   0        0          0         0       0  ...   \n",
       "...           ... .. .. .. ..  ..      ...        ...       ...     ...  ...   \n",
       "2074  ZWE_61_2006  0  2  0  0   0        0          0         0       0  ...   \n",
       "2075  ZWE_62_2007  1  0  0  0   1        0          0         0       0  ...   \n",
       "2076  ZWE_63_2008  1  0  0  0   0        0          0         0       0  ...   \n",
       "2077  ZWE_64_2009  0  3  0  0   0        0          0         0       0  ...   \n",
       "2078  ZWE_65_2010  0  0  0  0   0        0          0         0       0  ...   \n",
       "\n",
       "      ﻿to  ﻿today  ﻿trinidad  ﻿twenty-four  ﻿two  ﻿uruguay  ﻿we  ﻿yesterday  \\\n",
       "0       0       0          0             0     0         0    0           0   \n",
       "1       0       0          0             0     0         0    0           0   \n",
       "2       0       0          0             0     0         0    0           0   \n",
       "3       0       0          0             0     0         0    0           0   \n",
       "4       0       0          0             0     0         0    0           0   \n",
       "...   ...     ...        ...           ...   ...       ...  ...         ...   \n",
       "2074    0       0          0             0     0         0    0           0   \n",
       "2075    0       0          0             0     0         0    0           0   \n",
       "2076    0       0          0             0     0         0    0           0   \n",
       "2077    0       0          0             0     0         0    0           0   \n",
       "2078    0       0          0             0     0         0    0           0   \n",
       "\n",
       "      ﻿you  ﻿your  \n",
       "0        0      0  \n",
       "1        0      0  \n",
       "2        0      0  \n",
       "3        0      0  \n",
       "4        0      0  \n",
       "...    ...    ...  \n",
       "2074     0      0  \n",
       "2075     0      0  \n",
       "2076     0      0  \n",
       "2077     0      0  \n",
       "2078     0      0  \n",
       "\n",
       "[2079 rows x 31112 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfDTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4da3dde-7843-4b0b-af44-7a4f4b7c4c10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec81b90-ead3-43c7-84c1-e7694ca6c71f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1065522-74e0-421e-bfd1-14c154cc5e47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9e747e-7f20-49fa-acfd-bae375d0e5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8db037-3a7e-448a-9344-926f254fe503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5eed45-25dc-4e02-91e1-03790e61d147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c60f29-9212-4e83-905c-24074868b9ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aafbd05a-554c-4e48-b5c6-82066b1473ae",
   "metadata": {},
   "source": [
    "## Part 2: TF-IDF matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcdf8ac-f2ff-4267-8d23-21412a9e61e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d25145a-692a-45a0-b986-71241ac10ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18520ef8-7085-43c1-bb67-deb649ce4bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155d0000-7697-4ae6-9ccb-85b170afa199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fa1ed19-6180-4821-9d5a-12cd3edcf023",
   "metadata": {},
   "source": [
    "## Part 3: Dictionar Approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4363d0-7678-44a0-b8a6-809780e3aa51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38355fc3-bafb-4288-b135-a23ff39cd8ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5deddcc-fa4c-423d-a971-2a04505a7ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f485cd-db5a-44a7-b55f-ce46aa96ab2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
